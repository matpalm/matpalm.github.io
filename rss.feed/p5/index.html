 <head>
	<title>should i read it? markov chains</title>
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <link rel=stylesheet href="style.css" type="text/css">
 </head>
<body>

<h1>simple supervised learning</h1>
<h2>part 5: should i read it? markov chains</h2>

<h2>so far</h2>

<p>
so far we have considered 
<ul>
<li><a href="../p2">whether a word occurs for a given class (read or ignore)</a></li>
<li><a href="../p3">the frequency of words per class</a></li>
<li><a href="../p4">the frequency of words per test article</a></li>
</ul>
</p>

<p>now lets try markov chains; a technique that will consider the actual sequence of words</p>

<h2>whats a markov chain then?</h2>

<p>a markov chain is a way of modelling the probabisitic transistions between a number of states</p>

<p>
lets do an example and model the road rage levels of two people, calm carl and agro arnold</br>
carl and arnold can be in one of two states; calm or agro</br>
</p>

<p>
if carl is calm there's a 70% chance he'll stay calm and a 30% chance he'll lose it and turn agro</br>
once he's agro there's only 10% chance he'll stay agro, the other 90% of the time he becomes calm again
</p>

<p>
arnold of the other hand only has a 30% of staying calm, and once he's agro has a 50% chance of staying agro
</p>
  
<p>
<img src="calm_carl.png" /><img src="agro_arnold.png" />
</p>

<p>
then given a sequence of <strong>calm</strong> and <strong>agro</strong> states we can compare it to both chains and see which person it was likely to be
</p>

<p>
eg consider <strong>calm -> calm -> agro -> agro</strong></br>
</p>

<p>
the probability of carl's behaviour being like this is</br>
<tt>
= p(calm -> calm) . p(calm -> agro) . p(agro -> agro)    </br>
= 0.7 . 0.3 . 0.1</br>
= 0.021
</tt>
</p>

<p>
the probability for this being an example of arnold's behaviour is</br>
<tt>= p(calm -> calm) x p(calm -> agro) x p(agro -> agro)</tt></br>
<tt>= 0.3 x 0.7 x 0.5</tt></br>
<tt>= 0.105</tt></br>
</p>

<p>
which after normalisation gives</br>
carl <tt>= 0.021 / 0.126 = 14%</tt></br>
arnold <tt>= 0.105 / 0.126 = 83%</tt></br>
so it's far more likely this was arnold
</p>

<h2>markov chains from articles</h2>

<p>
an article in our classification problem can be represented as a markov chain where the nodes are words and transistions between words exist for adjacent words in an article</br>
</p>

<p>
eg the article <tt>'the end is the beginning is the end'</tt> can be represented by the chain</br>
<img src="the_end.png"/>
</p>

<p>from this we can see that <tt>is</tt> always follows <tt>beginning</tt> and <tt>end</tt> follows <tt>the</tt> 2/3rds of the time</br>

<p>
using this chain we can decide on the probabilities of other articles having been generated by the system that generated this one</br>
eg which of <tt>'the end is the end'</tt> and <tt>'the beginning is the beginning'</tt> is more likely?
</p>

<p>
define <tt>p(word1 -> word2)</tt> as the probabiltiy of word2 following word1 in an article</br>
</p>

<p><tt>
p('the end is the end')</br>
= p(the -> end) x p(end -> is) x p(is -> the) x p(the -> end)</br>
= 2/3 x 1/2 x 1/1 x 2/3</br>
= 2/9</br>
</tt></p>

<p><tt>
p('the beginning is the beginning')</br>
= p(the -> beginning) x p(beginning -> is) x p(is -> the) x p(the -> beginning)</br>
= 1/3 x 1/1 x 1/1 x 1/3</br>
= 1/9
</tt></p>

<p>
so <tt>'the end is the end'</tt> is twice as likely as <tt>'the beginning is the beginning'</tt>
</p>

<p>
multiple articles can be used to build a markov chain representing a particular feed</br>
eg the chain for the two articles <tt>'the end is the beginning is the end'</tt> and <tt>'the end of the road'</tt> is</br>
<img src="the_end_2.png"/>
</p>

<h2>the zero probability problem, again</h2>

<p>
given our two article example we have clear transistion probabilities for <tt>p(the -> road)</tt> and <tt>p(end->of)</tt></br>
but what are the values for <tt>p(the -> is)</tt>, <tt>p(blah -> is)</tt> or  even <tt>p(blah -> foo)</tt>?</br>
</p>

<p>
strictly these are all zero probabilties but we've seen previously how zeros clobber everything so we should assign these as 0/N and apply a laplace estimator</br>
but the question is; what N to use?</br>
</p>

<p>
for <tt>p(the -> is)</tt> 0/3 might be sensible since there are 3 edges in total leaving <tt>'the'</tt></br>
</p>

<p>
<tt>p(blah -> is)</tt> is a bit harder though since there are no edges leaving <tt>'blah'</tt></br>
there are edges entering <tt>'is'</tt> but the probabilities are driven by <tt>p(a -> b)</tt> not <tt>p(b &lt;- a)</tt>
</p>

<p>
<tt>p(blah -> foo)</tt> is harder still since we have no info either way on nodes <tt>'blah' and 'foo'</tt>
</p>

<p>
we'll start with the simplest of all and just assign all these cases to the low sensible probability of <tt>0 / total_number_of_edges</tt> and see how we go</br>
</p>

<h2>the first and last words of an article</h2>

<p>
special consideration can also be made to the frist and last words of an article when building a chain</br>
we can include special nodes for START and END in a chain and then </br>
for articles that start with <tt>'word'</tt> we can include an edge from <tt>START -> 'word'</tt></br>
for articles that end with <tt>'word'</tt> we can include an edge from <tt>'word' -> END</tt></br>
</p>

<p>
revisiting the chain for two articles <tt>'the end is the beginning is the end'</tt> and <tt>'end of the road'</tt> we have</br>
<img src="the_end_3.png"/>
</p>

<p>
we can ask the question</br>
which of <tt>'the end of road end'</tt> and <tt>'beginning of the road'</tt> is more likely?
</p>

<p><tt>
p('the end of road end')</br>
= p(START -> the) x p(the -> end) x p(end -> of) x p(of -> road) x p(road -> end) x p(end -> END)</br>
= 1/2 x 3/5 x 1/3 x 0/15 x 0/15 x 1/3</br>
= 15/30 x 18/30 x 10/30 x 0/30 x 0/30 x 10/30</br>
= 16/36 x 19/36 x 11/36 x 1/36 x 1/36 x 11/36 (with estimator)</br>
=  0.000017
</tt></p>

<p><tt>
p('beginning of the road')</br>
= p(start -> beginning) x p(beginning -> of) x p(of -> the) x p(the -> road) x p(road -> END)</br>
= 0/15 x 0/15 x 1/1 x 1/5 x 1/1</br>
= 0/15 x 0/15 x 15/15 x 3/15 x 15/15</br>
= 1/20 x 1/20 x 16/20 x 4/20 x 16/20 (with estimator)</br>
= 0.00032</br>
</tt></p>

<p>
after normalisation gives</br>
p('the end of road end') <tt>= 0.000017 / 0.000337 = 5%</tt></br>
p('beginning of the road') <tt>= 0.00032 / 0.000337 = 95%</tt></br>
so <tt>'beginning of the road'</tt> is a more probable match to these two articles
</p>

<h2>digression: underflow and the magic of logarithms</h2>

<p>
notice in the last example how our prenormalised probabilities are getting to be pretty small numbers</br>
it's not going to take long before the numbers are less than a machine can accurately handle</br>
what can we do about it? logarithms save the day!
</p>

<p>
consider the two probabilities products we had from our first carl vs arnold example</br>
carl was <tt>0.7 x 0.3 x 0.1</tt>, arnold was <tt>0.3 x 0.7 x 0.5</tt></br>
</p>

<p>
it turns out in this case, and in fact all the cases we've considered to date,</br>
we're not interested in the <em>actual</em> values of the probabiltity sums</br>
just whether one is greater than another
</p>

<p>
we're trying to decide if</br>
<tt>0.7 x 0.3 x 0.1 &gt; 0.3 x 0.7 x 0.5</tt></br>
</p>

<p>
recall from high school maths the following two facts about logarithms</br>
1) they preserve order; ie <tt>log(a) > log(b) if a > b</tt></br>
2) they <em>reduce</em> multiplication to addition; ie <tt>log(ab) = log(a) + log(b)</tt></br
</tt>
</p>

<p>
so <tt>0.7 x 0.3 x 0.1 &gt; 0.3 x 0.7 x 0.5</tt></br>
is equivalent to <tt>log(0.7 x 0.3 x 0.1) &gt; log(0.3 x 0.7 x 0.5)</tt> (from 1)</br>
is equivalent to <tt>log(0.7) + log(0.3) + log(0.1) &gt; log(0.3) + log(0.7) + log(0.5)</tt> (from 2)</br>
</p>

<p>
bye bye multiplication of really small numbers, hellooooo high precision comparisons :)
</p>

</p>
<h2>markov chains for our article classification problem</h2>

<p>
so coming back to our classification problem we can build two chains; one for articles to read and one for articles to ignore</br>
each new article can be compared to each chain to see which is more likely to be applicable</br>
how does it compare to our previous techniques?</br>
</p>

<p>
but first does it do better including or excluding the start and end probabilities?</br>
turns out it's slightly better when we include these probabilities</br>
</p>

<p>
and how does it do against our other classifier methods?</br>
pretty poorly actually...</br>
and it's interesting how wildly varying the markov chain results are</br>
</p>

<p>
<img src="markov_chain_comparison.png"/>
<img src="classifier_comparison.png"/>
</p>

<p>view the code at <a href="http://github.com/matpalm/rss-feed-experiments">github.com/matpalm/rss-feed-experiments</a></p>
<p>also download <a href="dot_files.tar.bz2">the dot files</a> used to generate the markov chain images</p>
<small>july 2008</small>
</body>
