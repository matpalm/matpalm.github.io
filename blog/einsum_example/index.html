


<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" 
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
    
  <title>brain of mat kelcey...</title>
<link rel="alternate" type="application/rss+xml" title="RSS 2.0" href="/blog/feed" />
<link rel="alternate" type="application/atom+xml" title="Atom 1.0"
href="/blog/feed/atom/index.xml" />
<link rel='stylesheet' href='/css/pygments_murphy.css' type='text/css' />
<link rel='stylesheet' href='/css/table.css' type='text/css' />
<link rel="stylesheet" href="/css/prettify.css" type="text/css" />
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script type="text/javascript" src="/js/prettify.js"></script>


  </head>
  <body onload="prettyPrint()">
    <div id="content">
      
  <div style="float:right">
<form action="http://www.google.com/search" method="get" class="roundtopsmall">
 <input value="matpalm.com" name="sitesearch" type="hidden">
 <input size="25" name="q" id="query" type="text" value="">&nbsp;
 <input name="Search" value="Search" type="submit">
</form>
</div>


<div style="float:right; padding-right:3em">
<a href="http://twitter.com/mat_kelcey"><img src="/blog/imgs/twit.png"></img></a>
<a href="https://github.com/matpalm"><img src="/blog/imgs/github.png"></img></a>
</div>

<h1><a href="/blog">brain of mat kelcey...</a></h1>

<hr/>


      <div id="main_block">
        <div id="prose_block">
          

<div class="blog_post">
  <a name="an-illustrative-einsum-example"></a>
  <h2 class="blog_post_title"><a href="/blog/einsum_example" rel="bookmark" title="Permanent Link to an illustrative einsum example">an illustrative einsum example</a></h2>
  <small>May 27, 2020 at 12:00 AM | categories:

<a href='/blog/tag/talk'>talk</a>, <a href='/blog/tag/short_tute'>short_tute</a>
</small><p/>
  <div class="post_prose">
    
  <h1>intro</h1>
<p>recently i changed what was quite clumsy looking code in something more
   elegant using a cool function in numpy called
   <a href="https://numpy.org/doc/stable/reference/generated/numpy.einsum.html">einsum</a>
   and felt it was worth writing up.
</p>
<p>this example is just going to be using numpy, but einsum is also provided in
   <a href="https://www.tensorflow.org/api_docs/python/tf/einsum">tensorflow</a>,
   <a href="https://jax.readthedocs.io/en/latest/_autosummary/jax.numpy.einsum.html">jax</a>
   and <a href="https://pytorch.org/docs/master/generated/torch.einsum.html">pytorch</a>
</p>
<p>there's also <a href="https://colab.research.google.com/drive/1kmt2cNFK7IGRhY1rXgqLVX3GsNc4Ybsh?usp=sharing">a terser colab version</a> of this post if you're prefer to walk through
   that.
</p>
<p>and for a video walkthrough of this see...
</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/SOaYrnQtd9g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<h1>example walkthrough</h1>
<p>the only user defined function we are going to use is this little <code>rnd</code>
   one to make random arrays of various sizes.
</p>
<pre class="prettyprint"><code class="language-python">&gt;&gt;&gt; import numpy as np

&gt;&gt;&gt; def rnd(*args):
&gt;&gt;&gt;     return np.random.random(args)
</code></pre>

<p>let's start with a fundamental operation, the matrix multiply.
   numpy provides it through <code>matmul</code> function which in this case is taking
   an <code>(i, j)</code> sized matrix and a <code>(j, k)</code> sized one and producing an
   <code>(i, k)</code> result; the classic 2d matrix multiply.
</p>
<pre class="prettyprint"><code class="language-python">&gt;&gt;&gt; np.matmul(rnd(4, 5), rnd(5, 6)).shape

(4, 6)
</code></pre>

<p>there's a number of interpretations of what a matrix multiply
   represents and a common one i use a lot is calculating,
   in batch, a bunch of pairwise dot products. if we have <code>S1</code> and <code>S2</code>,
   both of which represent some set of embeddings, in this case
   32d embeddings, 5 for <code>S1</code> and 10 for <code>S2</code>, if we want to calculate all pairwise
   combos we can use a matrix multiply. but note we need to massage
   <code>S2</code> a bit; a matrix multiple wants the inner dimension to match so
   we need to transpose <code>B</code> to make it (32, 10)
</p>
<pre class="prettyprint"><code class="language-python">&gt;&gt;&gt; S1 = rnd(5, 32)
&gt;&gt;&gt; S2 = rnd(10, 32)
&gt;&gt;&gt; np.matmul(S1, S2.T).shape

(5, 10)
</code></pre>

<p>an important thing to note about <code>matmul</code> is that it automatically handles
   the idea of batching. for example a leading dimension of 10 makes
   it equivalent to 10 independent matrix multiplies. we could do this
   in a for loop but expressing it in a single <code>matmul</code> will most likely
   be faster as the underlying linear algebra libraries can kick in with
   a bunch of optimisations.
</p>
<pre class="prettyprint"><code class="language-python">>>> np.matmul(rnd(10, 4, 5),
>>>           rnd(10, 5, 6)).shape

(10, 4, 6)
</code></pre>

<p>and note that it can be multiple leading dimensions.
   all that matters it the last two axis follow the <code>i,j,k</code> rule.
</p>
<pre class="prettyprint"><code class="language-python">>>> np.matmul(rnd(10, 20, 30, 4, 5),
>>>           rnd(10, 20, 30, 5, 6)).shape

(10, 20, 30, 4, 6)
</code></pre>

<p>so let's talk about the real use case that led me to write
   this post. we have a <code>query</code> that i want to compare to 10 <code>keys</code> by
   using a dot product; basically an unnormalised attention / soft map lookup.
</p>
<pre class="prettyprint"><code class="language-python">>>> E = 32
>>> query_embedding = rnd(E)
>>> keys_embeddings = rnd(10, E)
</code></pre>

<p>even though <code>query</code> is a vector we can use <code>matmul</code> to do this because
   <code>matmul</code> can interpret the vector as either a row vector as below in v1
   ( i.e. a matrix of shape <code>(1, E)</code> ) or a column vector as in v2
   ( a matrix of shape <code>(E, 1)</code> ) where, note, that <code>keys</code> and <code>query</code>
   are swapped)
</p>
<pre class="prettyprint"><code class="language-python">>>> v1 = np.matmul(query_embedding, keys_embeddings.T)
>>> v2 = np.matmul(keys_embeddings, query_embedding)
>>> v1.shape, v2.shape, np.all(np.isclose(v1, v2))

((10,), (10,), True)
</code></pre>

<p>my actual use case though is wanting to do the <code>query</code> to 10 <code>keys</code>
   comparison, but across a "batch" of 100 independant sets. so if we
   want to use <code>matmul</code> in the batched form we need to do a bit
   of massaging of these two since the assumed behaviour of <code>matmul</code> will
   no longer work.
</p>
<pre class="prettyprint"><code class="language-python">>>> N = 100
>>> E = 32
>>> query_embeddings = rnd(N, E)
>>> keys_embeddings = rnd(N, 10, E)
</code></pre>

<p>firstly we need to be more explicit that the <code>query</code> embeddings
   represent N row vectors.
</p>
<pre class="prettyprint"><code class="language-python">>>> query_embeddings.reshape(N, 1, E).shape

(100, 1, 32)
</code></pre>

<p>secondly we need to do the transpose for <code>keys</code>, but this time we
   can't just use <code>.T</code>, we need to be explicit about keeping the
   leading axis the same, swapping only the final two.
</p>
<pre class="prettyprint"><code class="language-python">>>> keys_embeddings.transpose(0, 2, 1).shape

(100, 32, 10)
</code></pre>

<p>after doing these two transforms we get the matrices that will trigger the
   batch matrix multiply behaviour we want. note that we end
   up with that inner dimension of 1 still around.
</p>
<pre class="prettyprint"><code class="language-python">>>> np.matmul(query_embeddings.reshape(N, 1, E),
>>>           keys_embeddings.transpose(0, 2, 1)).shape

(100, 1, 10)
</code></pre>

<p>and if we don't want that inner axis, we can explicitly <code>squeeze</code> it away.
</p>
<pre class="prettyprint"><code class="language-python">>>> np.squeeze(np.matmul(query_embeddings.reshape(N, 1, E),
>>>                      keys_embeddings.transpose(0, 2, 1))).shape

(100, 10)
</code></pre>

<p>this all works but it felt clumsy to me. so let's go back through
   these examples but using <code>einsum</code> which gives us more explicit ways to
   define the calculation without the massaging of <code>query</code> and <code>keys</code> to
   make <code>matmul</code> work.
</p>
<p>we'll redo the matmul versions again first (denoted
   by <code>m</code>) followed by the einsum equivalents (denoted by <code>e</code>)
</p>
<p>let's start with matrix multiply. <code>einsum</code> take a <code>subscript</code> arg
   which describes the computation we want to do. the first part <code>ij,jk</code> is a
   comma seperated list of the dimensions of the inputs, in this case <code>A</code> and <code>B</code>
</p>
<p>the first input, <code>A</code>, is 2d with axis we're naming <code>i</code> and <code>j</code>.
   the second input, <code>B</code>, is 2d also, with axis we're naming <code>j</code> and <code>k</code>.
</p>
<p>the output we want <code>-&gt;ik</code> is 2d and takes the axis <code>i</code> and <code>k</code> with a reduction
   along <code>j</code>. this is exactly a matrix multiply.
</p>
<pre class="prettyprint"><code class="language-python">>>> A, B = rnd(4, 5), rnd(5, 6)
>>>
>>> m = np.matmul(A, B)
>>>
>>> e = np.einsum('ij,jk->ik', A, B)
>>>
>>> m.shape, e.shape, np.all(np.isclose(m, e))

((4, 6), (4, 6), True)
</code></pre>

<p>consider again the case of two sets of 32d embeddings <code>S1</code> and <code>S2</code> and
   wanting to get all the pairwise products. since the <code>j</code> is now the
   second axis we don't need to have the transpose.
</p>
<pre class="prettyprint"><code class="language-python">>>> S1, S2 = rnd(5, 32), rnd(10, 32)
>>>
>>> m = np.matmul(S1, S2.T)
>>>
>>> e = np.einsum('ij,kj->ik', S1, S2)
>>>
>>> m.shape, e.shape, np.all(np.isclose(m, e))

((5, 10), (5, 10), True)
</code></pre>

<p>in fact in <code>einsum</code> we can use whatever letters we like, so we're
   free to try to use the character subscripts as a weak form of documentation.
   we've basically got one letter to describe what the axis represents.
</p>
<pre class="prettyprint"><code class="language-python">>>> S1, S2 = rnd(5, 32), rnd(10, 32)
>>>
>>> m = np.matmul(S1, S2.T)
>>>
>>> e = np.einsum('ae,be->ab', S1, S2)
>>>
>>> m.shape, e.shape, np.all(np.isclose(m, e))

((5, 10), (5, 10), True)
</code></pre>

<p>next let's consider the batch form of a matrix multiply. recall: <code>matmul</code>
   handles this by default, but with <code>einsum</code> we have to be
   explicit about it. even still it's arguably clearer since we end up not
   having to understand the assumed behaviour of <code>matmul</code>.
</p>
<pre class="prettyprint"><code class="language-python">>>> A, B = rnd(10, 4, 5), rnd(10, 5, 6)
>>>
>>> m = np.matmul(A, B)
>>>
>>> e = np.einsum('nij,njk->nik', A, B)
>>>
>>> m.shape, e.shape, np.all(np.isclose(m, e))

((10, 4, 6), (10, 4, 6), True)
</code></pre>

<p>going back to our <code>query</code> vs <code>keys</code> comparison, let's consider the
   single instance case. one main thing that is different is we don't need
   to have any assumption about <code>query</code> being interpretable as a row
   or column matrix, we can just explictly describe the axis
   ( in this case it's just the 1d <code>e</code> ).
</p>
<pre class="prettyprint"><code class="language-python">>>> E = 32
>>>
>>> query_embedding = rnd(E)
>>> keys_embeddings = rnd(10, E)
>>>
>>> m = np.matmul(query_embedding, keys_embeddings.T)
>>>
>>> e = np.einsum('e,ke->k', query_embedding, keys_embeddings)
>>>
>>> m.shape, e.shape, np.all(np.isclose(m, e))

((10,), (10,), True)
</code></pre>

<p>and finally consider the batched version where we see the <code>einsum</code> version ends
   up being much simpler. we don't rely on any behaviour of <code>matmul</code> that forces
   us to change things to particular shapes. as before because we need to be
   explict about what we want in terms of reduction we finish with a much
   simpler expression that is much more direct.
</p>
<pre class="prettyprint"><code class="language-python">>>> N = 100
>>> E = 32
>>>
>>> query_embeddings = rnd(N, E)
>>> keys_embeddings = rnd(N, 10, E)
>>>
>>> m = np.squeeze(np.matmul(query_embeddings.reshape(N, 1, E),
>>>                          keys_embeddings.transpose(0, 2, 1)))
>>>
>>> e = np.einsum('ne,nke->nk', query_embeddings, keys_embeddings)
>>>
>>> m.shape, e.shape, np.all(np.isclose(m, e))

((100, 10), (100, 10), True)
</code></pre>

  </div>
</div>



<div id="disqus_thread"></div>
<script type="text/javascript">
  var disqus_url = "http://matpalm.com/blog/einsum_example";
</script>

        </div><!-- End Prose Block -->
      </div><!-- End Main Block -->
      <div id="footer" style="float:right;">
        
  <hr/>
  <p id="credits">
Powered by <a href="http://www.blogofile.com">Blogofile</a>.<br/>
<br/>
RSS feeds for <a href="/blog/feed/index.xml">Entries</a>
<br>
</p>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
try {
var pageTracker = _gat._getTracker("UA-10409220-1");
pageTracker._trackPageview();
} catch(err) {}</script>



      </div> <!-- End Footer -->
    </div> <!-- End Content -->
  </body>
</html>




